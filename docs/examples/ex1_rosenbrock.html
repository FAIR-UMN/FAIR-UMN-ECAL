
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Rosenbrock &#8212; NCVX PyGRANSO Documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tips" href="../mistakes.html" />
    <link rel="prev" title="Examples" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/PyGRANSO_logo_banner.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NCVX PyGRANSO Documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../install.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../settings/index.html">
   Settings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/standard_parameters.html">
     Standard Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/searching_direction.html">
     Searching Direction Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/steering_strategy.html">
     Steering Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/qp_parameters.html">
     QP Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/line_search.html">
     Line Search Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../settings/new_para.html">
     PyGRANSO New Options
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Rosenbrock
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mistakes.html">
   Tips
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../jusun.html">
   NCVX Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../citation.html">
   Citing PyGRANSO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../forum.html">
   Forum
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/examples/ex1_rosenbrock.ipynb.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/sun-umn/PyGRANSO"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/sun-umn/PyGRANSO/issues/new?title=Issue%20on%20page%20%2Fexamples/ex1_rosenbrock.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Problem-Description">
   Problem Description
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Modules-Importing">
   Modules Importing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Function-Set-Up">
   Function Set-Up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#User-Options">
   User Options
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Main-Algorithm">
   Main Algorithm
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#PyGRANSO-Restarting">
   PyGRANSO Restarting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Results-Logs">
   Results Logs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#LFBGS-Restarting">
   LFBGS Restarting
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Rosenbrock">
<h1>Rosenbrock<a class="headerlink" href="#Rosenbrock" title="Permalink to this headline">¶</a></h1>
<p>Minimize 2-variable nonsmooth Rosenbrock function, subject to a simple bound constraint. Taken from: <a class="reference external" href="http://www.timmitchell.com/software/GRANSO/">GRANSO</a> demo examples 1, 2, &amp; 3</p>
<div class="section" id="Problem-Description">
<h2>Problem Description<a class="headerlink" href="#Problem-Description" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\min_{x_1,x_2} w|x_1^2-x_2|+(1-x_1)^2,\]</div>
<div class="math notranslate nohighlight">
\[\text{s.t. }c_1(x_1,x_2) = \sqrt{2}x_1-1 \leq 0, c_(x_1,x_2)=2x_2-1\leq0,\]</div>
<p>where <span class="math notranslate nohighlight">\(w\)</span> is a constant (e.g., <span class="math notranslate nohighlight">\(w=8\)</span>)</p>
</div>
<div class="section" id="Modules-Importing">
<h2>Modules Importing<a class="headerlink" href="#Modules-Importing" title="Permalink to this headline">¶</a></h2>
<p>Import all necessary modules and add PyGRANSO src folder to system path.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pygranso.pygranso</span> <span class="kn">import</span> <span class="n">pygranso</span>
<span class="kn">from</span> <span class="nn">pygranso.pygransoStruct</span> <span class="kn">import</span> <span class="n">pygransoStruct</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Function-Set-Up">
<h2>Function Set-Up<a class="headerlink" href="#Function-Set-Up" title="Permalink to this headline">¶</a></h2>
<p>Encode the optimization variables, and objective and constraint functions.</p>
<p>Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="c1"># variables and corresponding dimensions.</span>
<span class="n">var_in</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;x2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]}</span>

<span class="k">def</span> <span class="nf">comb_fn</span><span class="p">(</span><span class="n">X_struct</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x1</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">X_struct</span><span class="o">.</span><span class="n">x2</span>

    <span class="c1"># objective function</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># inequality constraint, matrix form</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">x1</span><span class="o">-</span><span class="mi">1</span>
    <span class="n">ci</span><span class="o">.</span><span class="n">c2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x2</span><span class="o">-</span><span class="mi">1</span>

    <span class="c1"># equality constraint</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">f</span><span class="p">,</span><span class="n">ci</span><span class="p">,</span><span class="n">ce</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="User-Options">
<h2>User Options<a class="headerlink" href="#User-Options" title="Permalink to this headline">¶</a></h2>
<p>Specify user-defined options for PyGRANSO</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="c1"># option for switching QP solver. We only have osqp as the only qp solver in current version. Default is osqp</span>
<span class="c1"># opts.QPsolver = &#39;osqp&#39;</span>

<span class="c1"># set an intial point</span>
<span class="c1"># All the user-provided data (vector/matrix/tensor) must be in torch tensor format.</span>
<span class="c1"># As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.</span>
<span class="c1"># Also, please make sure the device of provided torch tensor is the same as opts.torch_device.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Main-Algorithm">
<h2>Main Algorithm<a class="headerlink" href="#Main-Algorithm" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Wall Time: </span><span class="si">{}</span><span class="s2">s&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.0.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  1.41421356237 ║  0.00000000000 ║ 1.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.579471   ║
   1 ║ 1.000000 │  0.70773811042 ║  0.70773811042 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 10.07366   ║
   2 ║ 1.000000 │  0.25401310554 ║  0.25401310554 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.198885   ║
   3 ║ 1.000000 │  0.21478744238 ║  0.21478744238 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.136352   ║
   4 ║ 1.000000 │  0.21422378595 ║  0.21422378595 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.332997   ║
   5 ║ 1.000000 │  0.15330884270 ║  0.15330884270 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.122691   ║
   6 ║ 1.000000 │  0.14804462353 ║  0.14804462353 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.012623   ║
   7 ║ 1.000000 │  0.10856024489 ║  0.10856024489 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.042111   ║
   8 ║ 1.000000 │  0.10482600240 ║  0.10482593538 ║ 6.70e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003212   ║
   9 ║ 0.590490 │  0.05930348165 ║  0.09776366663 ║ 0.001575 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.028507   ║
  10 ║ 0.590490 │  0.05288121922 ║  0.08955480909 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.013736   ║
  11 ║ 0.590490 │  0.05256976230 ║  0.08902735406 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 0.005027   ║
  12 ║ 0.590490 │  0.05213546649 ║  0.08829187029 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001898   ║
  13 ║ 0.590490 │  0.05097806280 ║  0.08624466915 ║ 5.14e-05 │   -  ║ S  │     4 │ 1.750000 ║     1 │ 2.18e-05   ║
  14 ║ 0.590490 │  0.05079563998 ║  0.08602286233 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     2 │ 3.00e-05   ║
  15 ║ 0.590490 │  0.05077733823 ║  0.08599186816 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 3.47e-04   ║
  16 ║ 0.590490 │  0.05071543228 ║  0.08588702943 ║ 2.70e-10 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.05e-05   ║
  17 ║ 0.590490 │  0.05067270160 ║  0.08581466510 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 3.74e-06   ║
  18 ║ 0.590490 │  0.05066273369 ║  0.08579778436 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     3 │ 1.64e-05   ║
  19 ║ 0.590490 │  0.05066184116 ║  0.08579627286 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     4 │ 1.09e-05   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 0.590490 │  0.05065742201 ║  0.08578809116 ║ 2.85e-07 │   -  ║ S  │     3 │ 1.500000 ║     4 │ 8.47e-07   ║
  21 ║ 0.228768 │  0.01962567651 ║  0.08578802937 ║ 1.27e-07 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    24 │ 1.19e-07 ║     4 │ 2.88e-07   ║
  22 ║ 0.228768 │  0.01962563551 ║  0.08578840563 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 8.95e-07   ║
  23 ║ 0.228768 │  0.01962558257 ║  0.08578817425 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     4 │ 6.35e-08   ║
  24 ║ 0.228768 │  0.01962531715 ║  0.08578701404 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 6.13e-08   ║
  25 ║ 0.228768 │  0.01962530099 ║  0.08578694338 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     4 │ 6.35e-08   ║
  26 ║ 0.228768 │  0.01962527238 ║  0.08578681833 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 6.36e-08   ║
  27 ║ 0.228768 │  0.01962526814 ║  0.08578679978 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 7.48e-08   ║
  28 ║ 0.228768 │  0.01962525407 ║  0.08578673829 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     4 │ 9.96e-08   ║
  29 ║ 0.228768 │  0.01962521414 ║  0.08578643555 ║ 1.94e-08 │   -  ║ S  │     8 │ 4.250000 ║     4 │ 2.00e-07   ║
  30 ║ 0.228768 │  0.01962521395 ║  0.08578643827 ║ 1.94e-08 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    33 │ 2.33e-10 ║     4 │ 2.52e-08   ║
  31 ║ 0.109419 │  0.00938668494 ║  0.08578653377 ║ 9.14e-09 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    27 │ 1.49e-08 ║     4 │ 1.22e-08   ║
  32 ║ 0.109419 │  0.00938667939 ║  0.08578656654 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     4 │ 8.19e-09   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578656654 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578632948 ║ 5.69e-07 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08578643763 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              32                                                                                      ║
Function evaluations:    153                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
Total Wall Time: 0.4226830005645752s
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</div>
<div class="section" id="PyGRANSO-Restarting">
<h2>PyGRANSO Restarting<a class="headerlink" href="#PyGRANSO-Restarting" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong> The following example shows how to set various PyGRANSO options (such as simpler ASCII printing) and how to restart PyGRANSO</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="c1"># By default PyGRANSO will print using extended ASCII characters to &#39;draw&#39; table borders and some color prints.</span>
<span class="c1"># If user wants to create a log txt file of the console output, please set opts.print_ascii = True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># By default, PyGRANSO prints an info message about QP solvers, since</span>
<span class="c1"># PyGRANSO can be used with any QP solver that has a quadprog-compatible</span>
<span class="c1"># interface.  Let&#39;s disable this message since we&#39;ve already seen it</span>
<span class="c1"># hundreds of times and can now recite it from memory.  ;-)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Try a very short run.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>

<span class="c1"># PyGRANSO&#39;s penalty parameter is on the *objective* function, thus</span>
<span class="c1"># higher penalty parameter values favor objective minimization more</span>
<span class="c1"># highly than attaining feasibility.  Let&#39;s set PyGRANSO to start off</span>
<span class="c1"># with a higher initial value of the penalty parameter.  PyGRANSO will</span>
<span class="c1"># automatically tune the penalty parameter to promote progress towards</span>
<span class="c1"># feasibility.  PyGRANSO only adjusts the penalty parameter in a</span>
<span class="c1"># monotonically decreasing fashion.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             |
Version 1.0.0                                                                                                    |
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   |
   1 | 34.86784 |  1509.66611872 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6038   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   3 | 12.15767 |  285.452828054 |  22.6935200208 | 9.552604 |   -  | S  |     2 | 2.000000 |     1 | 0.297144   |
   4 | 12.15767 |  264.999595731 |  21.0732808630 | 8.797697 |   -  | S  |     2 | 2.000000 |     1 | 0.603629   |
   5 | 4.239116 |  60.5144787250 |  12.1478493778 | 9.018338 |   -  | S  |     2 | 2.000000 |     1 | 0.111610   |
   6 | 4.239116 |  53.5399399407 |  10.5181947367 | 8.952094 |   -  | S  |     2 | 0.500000 |     1 | 0.164082   |
   7 | 3.815204 |  48.9917031616 |  10.4947962860 | 8.951912 |   -  | S  |     4 | 0.125000 |     1 | 0.033640   |
   8 | 3.815204 |  48.7011303503 |  10.4372013183 | 8.881076 |   -  | S  |     2 | 2.000000 |     1 | 0.018555   |
   9 | 3.815204 |  48.2564717826 |  10.3422772655 | 8.798572 |   -  | S  |     2 | 2.000000 |     1 | 0.057946   |
  10 | 3.815204 |  39.4225027901 |  9.27057783616 | 4.053355 |   -  | S  |     5 | 16.00000 |     1 | 0.001796   |
==================================================================================================================
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
Optimization results:                                                                                            |
==================================================================================================================
   F |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
  MF |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    35                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
<p>Let’s restart PyGRANSO from the last iterate of the previous run</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>
<span class="n">opts</span><span class="o">.</span><span class="n">opt_tol</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="c1"># PREPARE TO RESTART PyGRANSO IN FULL-MEMORY MODE</span>
<span class="c1"># Set the last BFGS inverse Hessian approximation as the initial</span>
<span class="c1"># Hessian for the next run.  Generally this is a good thing to do, and</span>
<span class="c1"># often it is necessary to retain this information when restarting (as</span>
<span class="c1"># on difficult nonsmooth problems, PyGRANSO may not be able to restart</span>
<span class="c1"># without it).  However, your mileage may vary.  In the test, with</span>
<span class="c1"># the above settings, omitting H0 causes PyGRANSO to take an additional</span>
<span class="c1"># 16 iterations to converge on this problem.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">H0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>     <span class="c1"># try running with this commented out</span>

<span class="c1"># When restarting, soln.H_final may fail PyGRANSO&#39;s initial check to</span>
<span class="c1"># assess whether or not the user-provided H0 is positive definite.  If</span>
<span class="c1"># it fails this test, the test may be disabled by setting opts.checkH0</span>
<span class="c1"># to false.</span>
<span class="c1"># opts.checkH0 = False       % Not needed for this example</span>

<span class="c1"># If one desires to restart PyGRANSO as if it had never stopped (e.g.</span>
<span class="c1"># to continue optimization after it hit its maxit limit), then one must</span>
<span class="c1"># also disable scaling the initial BFGS inverse Hessian approximation</span>
<span class="c1"># on the very first iterate.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.0.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 3.815204 │  39.4225027901 ║  9.27057783616 ║ 4.053355 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.161642   ║
   1 ║ 2.503156 │  27.1660390047 ║  9.40556725606 ║ 3.622442 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.052571   ║
   2 ║ 2.252840 │  24.6945188331 ║  9.60502524451 ║ 3.055934 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.123979   ║
   3 ║ 2.027556 │  22.2891608988 ║  9.93655318601 ║ 2.142243 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.327632   ║
   4 ║ 1.642320 │  17.8466452739 ║  10.2830257908 ║ 0.958623 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.398523   ║
   5 ║ 1.642320 │  13.1488213993 ║  8.00624651871 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 1.154525   ║
   6 ║ 1.642320 │  11.5460120591 ║  6.65815886309 ║ 0.611182 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.564767   ║
   7 ║ 1.642320 │  9.64643631604 ║  5.87366310852 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.133714   ║
   8 ║ 1.642320 │  3.21798697724 ║  1.95941493549 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.753217   ║
   9 ║ 1.642320 │  3.20698340411 ║  1.95271491909 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.220366   ║
  10 ║ 1.642320 │  2.59256069646 ║  1.57859624223 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.043082   ║
  11 ║ 1.642320 │  2.09671972770 ║  1.27668134739 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.278937   ║
  12 ║ 1.642320 │  1.73910377054 ║  1.05893091751 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.273996   ║
  13 ║ 1.642320 │  1.64784761383 ║  1.00336553528 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.197039   ║
  14 ║ 1.642320 │  1.52746248381 ║  0.93006367811 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016653   ║
  15 ║ 1.642320 │  1.39572672366 ║  0.84985048340 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.150180   ║
  16 ║ 1.642320 │  1.12391051398 ║  0.68434305758 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.020073   ║
  17 ║ 1.642320 │  0.91199315687 ║  0.55530772041 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.265923   ║
  18 ║ 1.642320 │  0.73621537898 ║  0.44827757835 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.274315   ║
  19 ║ 1.642320 │  0.66922940171 ║  0.40749017763 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.166023   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 1.642320 │  0.65673189601 ║  0.39988051374 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012112   ║
  21 ║ 1.642320 │  0.46186812731 ║  0.28122901468 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.086222   ║
  22 ║ 1.642320 │  0.39915827413 ║  0.24304532290 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.127273   ║
  23 ║ 1.642320 │  0.35431501107 ║  0.21574050158 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004660   ║
  24 ║ 1.642320 │  0.33232210837 ║  0.20234914160 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.164148   ║
  25 ║ 1.642320 │  0.25925238218 ║  0.15785737894 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.062718   ║
  26 ║ 1.642320 │  0.25600945034 ║  0.15588277522 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.118204   ║
  27 ║ 1.642320 │  0.21667523919 ║  0.13193238594 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003458   ║
  28 ║ 1.642320 │  0.17790982347 ║  0.10832833313 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.050594   ║
  29 ║ 1.642320 │  0.17051247205 ║  0.10382412570 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001414   ║
  30 ║ 1.642320 │  0.16160174138 ║  0.09672898541 ║ 0.002740 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.001201   ║
  31 ║ 1.642320 │  0.14809398483 ║  0.08991753054 ║ 4.21e-04 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.071809   ║
  32 ║ 1.642320 │  0.14522491546 ║  0.08842666871 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.006831   ║
  33 ║ 1.642320 │  0.14411244414 ║  0.08774929092 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001069   ║
  34 ║ 1.642320 │  0.14302671565 ║  0.08565902896 ║ 0.001581 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 9.51e-04   ║
  35 ║ 1.642320 │  0.14225247491 ║  0.08656823696 ║ 7.97e-05 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.008330   ║
  36 ║ 1.642320 │  0.14173105591 ║  0.08629927646 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.003548   ║
  37 ║ 1.642320 │  0.14147487321 ║  0.08614328819 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     2 │ 4.60e-04   ║
  38 ║ 1.642320 │  0.14129124284 ║  0.08603147664 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.36e-04   ║
  39 ║ 1.642320 │  0.14102011969 ║  0.08586637047 ║ 3.41e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 9.41e-06   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 1.642320 │  0.14092146669 ║  0.08580631945 ║ 4.09e-09 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 7.95e-07   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08580631945 ║ 4.09e-09 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08580631945 ║ 4.09e-09 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08603147664 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              40                                                                                      ║
Function evaluations:    83                                                                                      ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0.7071],
        [0.5000]], dtype=torch.float64)
</pre></div></div>
</div>
</div>
<div class="section" id="Results-Logs">
<h2>Results Logs<a class="headerlink" href="#Results-Logs" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong> opts below shows the importance of using an initial point that is neither near nor on a nonsmooth manifold, that is, the functions (objective and constraints) should be smooth at and <em>about</em> the initial point.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># Set a randomly generated starting point.  In theory, with probability</span>
<span class="c1"># one, a randomly selected point will not be on a nonsmooth manifold.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>   <span class="c1"># randomly generated is okay</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># we&#39;ll use this value of maxit later</span>
<span class="n">opts</span><span class="o">.</span><span class="n">opt_tol</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="c1"># However, (0,0) or (1,1) are on the nonsmooth manifold and if PyGRANSO</span>
<span class="c1"># is started at either of them, it will break down on the first</span>
<span class="c1"># iteration.  This example highlights that it is imperative to start</span>
<span class="c1"># PyGRANSO at a point where the functions are smooth.</span>

<span class="c1"># Uncomment either of the following two lines to try starting PyGRANSO</span>
<span class="c1"># from (0,0) or (1,1), where the functions are not differentiable.</span>

<span class="c1"># opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)     # uncomment this line to try this point</span>
<span class="c1"># opts.x0 = torch.zeros((2,1), device=device, dtype=torch.double)    # uncomment this line to try this point</span>

<span class="c1"># Uncomment the following two lines to try starting PyGRANSO from a</span>
<span class="c1"># uniformly perturbed version of (1,1).  pert_level needs to be at</span>
<span class="c1"># least 1e-3 or so to get consistently reliable optimization quality.</span>

<span class="c1"># pert_level = 1e-3</span>
<span class="c1"># opts.x0 = (torch.ones((2,1)) + pert_level * (torch.randn((2,1)) - 0.5)).to(device=device, dtype=torch.double)</span>
</pre></div>
</div>
</div>
<p>The opts below show how to use opts.halt_log_fn to create a history of iterates</p>
<p>NOTE: NO NEED TO CHANGE ANYTHING BELOW</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># SETUP THE LOGGING FEATURES</span>

<span class="c1"># Set up PyGRANSO&#39;s logging functions; pass opts.maxit to it so that</span>
<span class="c1"># storage can be preallocated for efficiency.</span>

<span class="k">class</span> <span class="nc">HaltLog</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">haltLog</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span>
                <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">):</span>

        <span class="c1"># DON&#39;T CHANGE THIS</span>
        <span class="c1"># increment the index/count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># EXAMPLE:</span>
        <span class="c1"># store history of x iterates in a preallocated cell array</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">penaltyfn_parts</span><span class="o">.</span><span class="n">tv</span><span class="p">)</span>

        <span class="c1"># keep this false unless you want to implement a custom termination</span>
        <span class="c1"># condition</span>
        <span class="n">halt</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">halt</span>

    <span class="c1"># Once PyGRANSO has run, you may call this function to get retreive all</span>
    <span class="c1"># the logging data stored in the shared variables, which is populated</span>
    <span class="c1"># by haltLog being called on every iteration of PyGRANSO.</span>
    <span class="k">def</span> <span class="nf">getLog</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># EXAMPLE</span>
        <span class="c1"># return x_iterates, trimmed to correct size</span>
        <span class="n">log</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
        <span class="n">log</span><span class="o">.</span><span class="n">x</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">f</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="n">log</span><span class="o">.</span><span class="n">tv</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tv</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">log</span>

    <span class="k">def</span> <span class="nf">makeHaltLogFunctions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">maxit</span><span class="p">):</span>
        <span class="c1"># don&#39;t change these lambda functions</span>
        <span class="n">halt_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">haltLog</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">penaltyfn_parts</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span><span class="n">get_BFGS_state_fn</span><span class="p">,</span> <span class="n">H_regularized</span><span class="p">,</span> <span class="n">ls_evals</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_gradients</span><span class="p">,</span> <span class="n">stat_vec</span><span class="p">,</span> <span class="n">stat_val</span><span class="p">,</span> <span class="n">fallback_level</span><span class="p">)</span>

        <span class="n">get_log_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">getLog</span><span class="p">()</span>

        <span class="c1"># Make your shared variables here to store PyGRANSO history data</span>
        <span class="c1"># EXAMPLE - store history of iterates x_0,x_1,...,x_k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span>       <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_iterates</span>  <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f</span>           <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tv</span>          <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Only modify the body of logIterate(), not its name or arguments.</span>
        <span class="c1"># Store whatever data you wish from the current PyGRANSO iteration info,</span>
        <span class="c1"># given by the input arguments, into shared variables of</span>
        <span class="c1"># makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO</span>
        <span class="c1"># has been terminated.</span>
        <span class="c1">#</span>
        <span class="c1"># DESCRIPTION OF INPUT ARGUMENTS</span>
        <span class="c1">#   iter                current iteration number</span>
        <span class="c1">#   x                   current iterate x</span>
        <span class="c1">#   penaltyfn_parts     struct containing the following</span>
        <span class="c1">#       OBJECTIVE AND CONSTRAINTS VALUES</span>
        <span class="c1">#       .f              objective value at x</span>
        <span class="c1">#       .f_grad         objective gradient at x</span>
        <span class="c1">#       .ci             inequality constraint at x</span>
        <span class="c1">#       .ci_grad        inequality gradient at x</span>
        <span class="c1">#       .ce             equality constraint at x</span>
        <span class="c1">#       .ce_grad        equality gradient at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)</span>
        <span class="c1">#       .tvi            total violation of inequality constraints at x</span>
        <span class="c1">#       .tve            total violation of equality constraints at x</span>
        <span class="c1">#       .tv             total violation of all constraints at x</span>
        <span class="c1">#       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)</span>
        <span class="c1">#       .tvi_l1         total violation of inequality constraints at x</span>
        <span class="c1">#       .tvi_l1_grad    its gradient</span>
        <span class="c1">#       .tve_l1         total violation of equality constraints at x</span>
        <span class="c1">#       .tve_l1_grad    its gradient</span>
        <span class="c1">#       .tv_l1          total violation of all constraints at x</span>
        <span class="c1">#       .tv_l1_grad     its gradient</span>
        <span class="c1">#       PENALTY FUNCTION VALUES</span>
        <span class="c1">#       .p              penalty function value at x</span>
        <span class="c1">#       .p_grad         penalty function gradient at x</span>
        <span class="c1">#       .mu             current value of the penalty parameter</span>
        <span class="c1">#       .feasible_to_tol logical indicating whether x is feasible</span>
        <span class="c1">#   d                   search direction</span>
        <span class="c1">#   get_BFGS_state_fn   function handle to get the (L)BFGS state data</span>
        <span class="c1">#                       FULL MEMORY:</span>
        <span class="c1">#                       - returns BFGS inverse Hessian approximation</span>
        <span class="c1">#                       LIMITED MEMORY:</span>
        <span class="c1">#                       - returns a struct with current L-BFGS state:</span>
        <span class="c1">#                           .S          matrix of the BFGS s vectors</span>
        <span class="c1">#                           .Y          matrix of the BFGS y vectors</span>
        <span class="c1">#                           .rho        row vector of the 1/sty values</span>
        <span class="c1">#                           .gamma      H0 scaling factor</span>
        <span class="c1">#   H_regularized       regularized version of H</span>
        <span class="c1">#                       [] if no regularization was applied to H</span>
        <span class="c1">#   fn_evals            number of function evaluations incurred during</span>
        <span class="c1">#                       this iteration</span>
        <span class="c1">#   alpha               size of accepted size</span>
        <span class="c1">#   n_gradients         number of previous gradients used for computing</span>
        <span class="c1">#                       the termination QP</span>
        <span class="c1">#   stat_vec            stationarity measure vector</span>
        <span class="c1">#   stat_val            approximate value of stationarity:</span>
        <span class="c1">#                           norm(stat_vec)</span>
        <span class="c1">#                       gradients (result of termination QP)</span>
        <span class="c1">#   fallback_level      number of strategy needed for a successful step</span>
        <span class="c1">#                       to be taken.  See bfgssqpOptionsAdvanced.</span>
        <span class="c1">#</span>
        <span class="c1"># OUTPUT ARGUMENT</span>
        <span class="c1">#   halt                set this to true if you wish optimization to</span>
        <span class="c1">#                       be halted at the current iterate.  This can be</span>
        <span class="c1">#                       used to create a custom termination condition,</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span>

<span class="n">mHLF_obj</span> <span class="o">=</span> <span class="n">HaltLog</span><span class="p">()</span>
<span class="p">[</span><span class="n">halt_log_fn</span><span class="p">,</span> <span class="n">get_log_fn</span><span class="p">]</span> <span class="o">=</span> <span class="n">mHLF_obj</span><span class="o">.</span><span class="n">makeHaltLogFunctions</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">maxit</span><span class="p">)</span>

<span class="c1">#  Set PyGRANSO&#39;s logging function in opts</span>
<span class="n">opts</span><span class="o">.</span><span class="n">halt_log_fn</span> <span class="o">=</span> <span class="n">halt_log_fn</span>

<span class="c1"># Main algorithm with logging enabled.</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>

<span class="c1"># GET THE HISTORY OF ITERATES</span>
<span class="c1"># Even if an error is thrown, the log generated until the error can be</span>
<span class="c1"># obtained by calling get_log_fn()</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">get_log_fn</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


<span class="ansi-yellow-fg">╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗
</span><span class="ansi-yellow-fg">║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║
</span><span class="ansi-yellow-fg">║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║
</span><span class="ansi-yellow-fg">║  To disable this notice, set opts.quadprog_info_msg = False                                   ║
</span><span class="ansi-yellow-fg">╚═══════════════════════════════════════════════════════════════════════════════════════════════╝
</span>═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.0.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.000000 │  5.91478160154 ║  5.51653284672 ║ 0.398249 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 9.144089   ║
   1 ║ 0.348678 │  0.62468632153 ║  1.79158287318 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 2.153127   ║
   2 ║ 0.348678 │  0.53421825751 ║  1.53212299950 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.269070   ║
   3 ║ 0.348678 │  0.19520379803 ║  0.55983902524 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.138582   ║
   4 ║ 0.348678 │  0.17201277586 ║  0.49332782323 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.074744   ║
   5 ║ 0.348678 │  0.13420574786 ║  0.38489832585 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.033149   ║
   6 ║ 0.348678 │  0.12140505653 ║  0.34818630166 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.061771   ║
   7 ║ 0.348678 │  0.10616098112 ║  0.30446672036 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.025510   ║
   8 ║ 0.348678 │  0.09861370484 ║  0.28282134339 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004640   ║
   9 ║ 0.348678 │  0.07435712849 ║  0.21325416183 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.033337   ║
  10 ║ 0.348678 │  0.07349145772 ║  0.21077144232 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.081071   ║
  11 ║ 0.348678 │  0.06086053106 ║  0.17454629843 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.060785   ║
  12 ║ 0.348678 │  0.05528000599 ║  0.15854150882 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.006487   ║
  13 ║ 0.348678 │  0.05415635969 ║  0.15531892272 ║ 0.000000 │   -  ║ S  │     5 │ 0.187500 ║     1 │ 0.142723   ║
  14 ║ 0.348678 │  0.05137077396 ║  0.14732994087 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012874   ║
  15 ║ 0.348678 │  0.04882162145 ║  0.14001904285 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.007669   ║
  16 ║ 0.348678 │  0.04687607525 ║  0.13443927084 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.45e-04   ║
  17 ║ 0.348678 │  0.04220315351 ║  0.12103746218 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.020577   ║
  18 ║ 0.348678 │  0.04085127012 ║  0.08516696610 ║ 0.007515 │   -  ║ S  │     4 │ 1.750000 ║     1 │ 0.006555   ║
  19 ║ 0.348678 │  0.03800712919 ║  0.09930640794 ║ 0.002332 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.020930   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  20 ║ 0.348678 │  0.03233074008 ║  0.09272365699 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 8.68e-04   ║
  21 ║ 0.121577 │  0.01110758374 ║  0.09136280137 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.003355   ║
  22 ║ 0.121577 │  0.01060454734 ║  0.08722519451 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.25e-04   ║
  23 ║ 0.121577 │  0.01049931349 ║  0.08635961832 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 3.08e-04   ║
  24 ║ 0.121577 │  0.01047461989 ║  0.08615650700 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     2 │ 6.81e-05   ║
  25 ║ 0.121577 │  0.01046947623 ║  0.08611419906 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 7.01e-05   ║
  26 ║ 0.121577 │  0.01045898771 ║  0.08602792815 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 7.99e-05   ║
  27 ║ 0.121577 │  0.01045690779 ║  0.08601082031 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 1.08e-04   ║
  28 ║ 0.121577 │  0.01044739431 ║  0.08580158663 ║ 1.20e-05 │   -  ║ S  │     9 │ 2.218750 ║     1 │ 6.63e-06   ║
  29 ║ 0.109419 │  0.00940025575 ║  0.08587490291 ║ 3.91e-06 │   -  ║ <span class="ansi-yellow-fg">SI</span> │    17 │ 1.53e-05 ║     2 │ 6.54e-07   ║
  30 ║ 0.109419 │  0.00939588755 ║  0.08587072155 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     3 │ 6.46e-07   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08587072155 ║ 0.000000 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08580454545 ║ 0.000000 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08580454545 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              30                                                                                      ║
Function evaluations:    75                                                                                      ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">log</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[5.516532846720021, 1.7915828731811967, 1.5321229994988945]
[tensor([[0.2745],
        [0.6991]], dtype=torch.float64), tensor([[0.4303],
        [0.0018]], dtype=torch.float64), tensor([[0.3361],
        [0.2494]], dtype=torch.float64)]
</pre></div></div>
</div>
</div>
<div class="section" id="LFBGS-Restarting">
<h2>LFBGS Restarting<a class="headerlink" href="#LFBGS-Restarting" title="Permalink to this headline">¶</a></h2>
<p><strong>(Optional)</strong></p>
<p>(Note that this example problem only has two variables!)</p>
<p>If PyGRANSO runs in limited-memory mode, that is, if opts.limited_mem_size &gt; 0, then PyGRANSO’s restart procedure is slightly different from the BFGS restarting, as soln.H_final will instead contain the most current L-BFGS state, not a full inverse Hessian approximation.</p>
<p>Instead the BFGS standard procedure, users should do the following: 1) If you set a specific H0, you will need to set opts.H0 to whatever you used previously. By default, PyGRANSO uses the identity for H0.</p>
<ol class="arabic simple" start="2">
<li><p>Warm-start PyGRANSO with the most recent L-BFGS data by setting: opts.limited_mem_warm_start = soln.H_final;</p></li>
</ol>
<p>NOTE: how to set opts.scaleH0 so that PyGRANSO will be restarted as if it had never terminated depends on the previously used values of opts.scaleH0 and opts.limited_mem_fixed_scaling.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set an infeasible initial point</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="mf">5.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

<span class="n">opts</span><span class="o">.</span><span class="n">print_ascii</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># default is 1000</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default is 1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>


<span class="c1"># By default, PyGRANSO uses full-memory BFGS updating.  For nonsmooth</span>
<span class="c1"># problems, full-memory BFGS is generally recommended.  However, if</span>
<span class="c1"># this is not feasible, one may optionally enable limited-memory BFGS</span>
<span class="c1"># updating by setting opts.limited_mem_size to a positive integer</span>
<span class="c1"># (significantly) less than the number of variables.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># start main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


==================================================================================================================
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             |
Version 1.0.0                                                                                                    |
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       |
==================================================================================================================
Problem specifications:                                                                                          |
 # of variables                     :   2                                                                        |
 # of inequality constraints        :   2                                                                        |
 # of equality constraints          :   0                                                                        |
==================================================================================================================
Limited-memory mode enabled with size = 1.                                                                       |
NOTE: limited-memory mode is generally NOT                                                                       |
recommended for nonsmooth problems.                                                                              |
==================================================================================================================
     | &lt;--- Penalty Function --&gt; |                | Total Violation | &lt;--- Line Search ---&gt; | &lt;- Stationarity -&gt; |
Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   |
=====|===========================|================|=================|=======================|====================|
   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   |
   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   |
   4 | 12.15767 |  262.610250639 |  20.8774186596 | 8.789579 |   -  | S  |     2 | 2.000000 |     1 | 0.604009   |
   6 | 4.239116 |  57.9458175917 |  11.5708792009 | 8.895520 |   -  | S  |     3 | 0.750000 |     1 | 0.165224   |
   8 | 1.642320 |  26.2056730861 |  10.5532019880 | 8.873935 |   -  | S  |     1 | 1.000000 |     1 | 0.027766   |
  10 | 1.642320 |  25.9163909350 |  10.4174724535 | 8.807564 |   -  | S  |     2 | 2.000000 |     1 | 0.021455   |
==================================================================================================================
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   |
Optimization results:                                                                                            |
==================================================================================================================
   F |          |                |  10.4174724535 | 8.807564 |   -  |    |       |          |       |            |
  MF |          |                |  75.6886238113 | 8.192103 |   -  |    |       |          |       |            |
==================================================================================================================
Iterations:              10                                                                                      |
Function evaluations:    29                                                                                      |
PyGRANSO termination code: 4 --- max iterations reached.                                                         |
==================================================================================================================
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Restart</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">pygransoStruct</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">torch_device</span> <span class="o">=</span> <span class="n">device</span>
<span class="c1"># set the initial point and penalty parameter to their final values from the previous run</span>
<span class="n">opts</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">x</span>
<span class="n">opts</span><span class="o">.</span><span class="n">mu0</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">final</span><span class="o">.</span><span class="n">mu</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">opts</span><span class="o">.</span><span class="n">quadprog_info_msg</span>  <span class="o">=</span> <span class="kc">False</span>
<span class="n">opts</span><span class="o">.</span><span class="n">print_frequency</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_warm_start</span> <span class="o">=</span> <span class="n">soln</span><span class="o">.</span><span class="n">H_final</span>
<span class="n">opts</span><span class="o">.</span><span class="n">scaleH0</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># In contrast to full-memory BFGS updating, limited-memory BFGS</span>
<span class="c1"># permits that H0 can be scaled on every iteration.  By default,</span>
<span class="c1"># PyGRANSO will reuse the scaling parameter that is calculated on the</span>
<span class="c1"># very first iteration for all subsequent iterations as well.  Set</span>
<span class="c1"># this option to false to force PyGRANSO to calculate a new scaling</span>
<span class="c1"># parameter on every iteration.  Note that opts.scaleH0 has no effect</span>
<span class="c1"># when opts.limited_mem_fixed_scaling is set to true.</span>
<span class="n">opts</span><span class="o">.</span><span class="n">limited_mem_fixed_scaling</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Restart PyGRANSO</span>
<span class="n">opts</span><span class="o">.</span><span class="n">maxit</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># increase maximum allowed iterations</span>

<span class="c1"># Main algorithm</span>
<span class="n">soln</span> <span class="o">=</span> <span class="n">pygranso</span><span class="p">(</span><span class="n">var_spec</span> <span class="o">=</span> <span class="n">var_in</span><span class="p">,</span><span class="n">combined_fn</span> <span class="o">=</span> <span class="n">comb_fn</span><span class="p">,</span> <span class="n">user_opts</span> <span class="o">=</span> <span class="n">opts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║
Version 1.0.0                                                                                                    ║
Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                                       ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
Problem specifications:                                                                                          ║
 # of variables                     :   2                                                                        ║
 # of inequality constraints        :   2                                                                        ║
 # of equality constraints          :   0                                                                        ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
<span class="ansi-yellow-fg">Limited-memory mode enabled with size = 1.                                                                      </span> ║
<span class="ansi-yellow-fg">NOTE: limited-memory mode is generally NOT                                                                      </span> ║
<span class="ansi-yellow-fg">recommended for nonsmooth problems.                                                                             </span> ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
   0 ║ 1.642320 │  25.9163909350 ║  10.4174724535 ║ 8.807564 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.142170   ║
   2 ║ 1.642320 │  13.8167164344 ║  6.50516654793 ║ 3.133149 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.836712   ║
   4 ║ 1.642320 │  6.43976368442 ║  3.92113741712 ║ 1.49e-13 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 3.895256   ║
   6 ║ 1.642320 │  4.83429798431 ║  2.94357800080 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.051607   ║
   8 ║ 1.642320 │  4.65433194405 ║  2.83399764834 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018191   ║
  10 ║ 1.642320 │  3.93915291951 ║  2.39852899290 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.007871   ║
  12 ║ 1.642320 │  3.11071061794 ║  1.89409493820 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.062960   ║
  14 ║ 1.642320 │  2.65454712546 ║  1.61633944493 ║ 0.000000 │   -  ║ S  │     7 │ 0.046875 ║     1 │ 0.586153   ║
  16 ║ 1.642320 │  2.32279937155 ║  1.41434002467 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.126551   ║
  18 ║ 1.642320 │  2.07095045978 ║  1.26099057897 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018684   ║
  20 ║ 1.642320 │  1.90771826108 ║  1.16159937250 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.021229   ║
  22 ║ 1.642320 │  1.59963185116 ║  0.97400721713 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.037486   ║
  24 ║ 1.642320 │  1.37732033554 ║  0.83864293283 ║ 0.000000 │   -  ║ S  │     3 │ 0.750000 ║     1 │ 0.208485   ║
  26 ║ 1.642320 │  1.21815586560 ║  0.74172854449 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.033736   ║
  28 ║ 1.642320 │  1.01220061824 ║  0.61632350383 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.002341   ║
  30 ║ 1.642320 │  0.84526282661 ║  0.51467598178 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.031024   ║
  32 ║ 1.642320 │  0.72210442469 ║  0.43968549429 ║ 0.000000 │   -  ║ S  │     4 │ 0.375000 ║     1 │ 0.165416   ║
  34 ║ 1.642320 │  0.68375411607 ║  0.41633419797 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.010354   ║
  36 ║ 1.642320 │  0.62473059481 ║  0.38039509382 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.018070   ║
  38 ║ 1.642320 │  0.54461333491 ║  0.33161212585 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.533683   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
     ║ &lt;--- Penalty Function --&gt; ║                ║ Total Violation ║ &lt;--- Line Search ---&gt; ║ &lt;- Stationarity -&gt; ║
Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║
═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣
  40 ║ 1.642320 │  0.38148532649 ║  0.23228436028 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.005209   ║
  42 ║ 1.642320 │  0.34267381138 ║  0.20865223780 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.099888   ║
  44 ║ 1.642320 │  0.23778293036 ║  0.14478474538 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.084472   ║
  46 ║ 1.642320 │  0.22843538334 ║  0.13909307436 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002119   ║
  48 ║ 1.642320 │  0.19511910847 ║  0.11744870451 ║ 0.002231 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 2.756868   ║
  50 ║ 1.642320 │  0.14343687320 ║  0.08733793941 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.001760   ║
  52 ║ 1.642320 │  0.14327776834 ║  0.08653941321 ║ 6.90e-04 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 4.74e-04   ║
  54 ║ 1.197252 │  0.10274997930 ║  0.08582154855 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     2 │ 9.34e-06   ║
  56 ║ 1.197252 │  0.10272513127 ║  0.08580003011 ║ 9.15e-07 │   -  ║ S  │     1 │ 1.000000 ║     2 │ 6.54e-08   ║
  58 ║ 1.197252 │  0.10271231607 ║  0.08578987986 ║ 2.52e-07 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 1.14e-07   ║
  60 ║ 1.077526 │  0.09243733513 ║  0.08578659987 ║ 1.19e-08 │   -  ║ S  │     2 │ 0.500000 ║     4 │ 4.63e-09   ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║
Optimization results:                                                                                            ║
═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣
   F ║          │                ║  0.08578659987 ║ 1.19e-08 │   -  ║    │       │          ║       │            ║
   B ║          │                ║  0.08578659987 ║ 1.19e-08 │   -  ║    │       │          ║       │            ║
  MF ║          │                ║  0.08580650897 ║ 0.000000 │   -  ║    │       │          ║       │            ║
═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣
Iterations:              60                                                                                      ║
Function evaluations:    137                                                                                     ║
PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║
═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</pre></div></div>
</div>
</div>
</div>


              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="index.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Examples</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../mistakes.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Tips</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Buyun Liang<br/>
        
            &copy; Copyright 2021-2022, Buyun Liang.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>